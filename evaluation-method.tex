
\section{Evaluation Method}

The evaluation process carried out using the goodness-of-fit (GOF) method proposed by \citet{Anderson_2004_Proc}, with minor modifications introduced by \citet{Taborda_2013_BSSA}. The method compares synthetics against data, at locations where records were available for the simulated events, for the following parameters: Arias intensity integral (C1), energy integral (C2), Arias intensity value (C3), total energy (C4), peak acceleration (C5), peak velocity (C6), peak displacement (C7), response spectrum (C8), Fourier amplitude spectrum (C9), cross correlation (C10), and strong-phase duration (C11). Each parameter is mapped onto a numerical scale ranging from 0 to 10, with 0 for the worsth and 10 for the best match between two signals. The values obtained for a given pair of signals for each of the eleven scores are combined using the expression: 
%
\begin{equation}
	\mathrm{S} = \frac{1}{9} \left( 
		\frac{\mathrm{C}1+\mathrm{C}2}{2} +
		\frac{\mathrm{C}3+\mathrm{C}4}{2} +
		\sum_{i=5}^{11} \mathrm{C}i
	\right)
	\hspace{0.25em}.
	\label{eq:s}
\end{equation}

Following the guidelines suggested by \citet{Anderson_2004_Proc}, this scoring procedure is applied to each pair of data and synthetics using compatible ``broadband'' sets, and a series of band-pass filtered versions of the signals or sub-bands, SB$_1$, SB$_2$, and SB$_3$. The results of S from equation (\ref{eq:s}) for the broadband (BB) and each of the sub-bands (SB$_i$) are then combined to obtain a final score (FS), define as:
%
\begin{equation}
	\mathrm{FS} = \frac{1}{4} \left( \mathrm{BB} + \sum^3_{i=1} \mathrm{SB}_i \right)
	\hspace{0.25em}.
	\label{eq:fs}
\end{equation}

We used signals band-pass filtered between 0.1 and 1.0 Hz for BB, and between 0.1 and 0.25~Hz, 0.25 and 0.5~Hz, and 0.5 and 1~Hz for SB$_1$, SB$_2$, and SB$_3$, respectively. The upper frequency limit of 1~Hz was based on the maximum frequency of the simulations. The lower limit of 0.1~Hz, on the other hand, was determined by the need for minimizing instrumental and numerical processing issues at the low frequencies (0--0.1~Hz), which can be introduced when processing strong motion and broadband records to obtain velocities and displacements. This also helps eliminate permanent displacements in the synthetics extracted at locations near the epicenter, especially for shallower earthquakes. 

Before running the comparison process, signals are also (sub)-sampled to have the same time-step size, $\Delta t$. We chose a common $\Delta t$ equal 0.1 s, and used a decimation corner (low-pass) frequency of 2~Hz for the records. This corresponds to a Nyquist frequency of 5~Hz, or five times the simulation maximum frequency. In addition, both data and synthetics were synchronized using the earthquake times (shown in Table \ref{tab:events}) as reference. Synthetics were synchronized assuming that the earthquake time corresponds to the instant at which the source slip-time function is at half the total rise time. Data were synchronized using the time-stamp on the record. We cut or zero-padded the records at the beginning depending on whether the station channel started recording before or after the earthquake time. When zero-padding, a tapper filter in time was applied at the beginning of the record. Once the signals have been synchronized in terms of start-time, they are also matched to have the same length, using the shortest of the two to determine the length used for comparisons. Applying these filters equally to data and synthetics, using a common $\Delta t$, and synchronizing the start- and end-time of each pair of signals provides a maximum level of consistency in both the frequency and time domains, which minimizes the numerical discrepancies that could arise from the comparisons performed using the different metrics C1 through C11.

Additional details about the original parameters proposed by \citet{Anderson_2004_Proc} and the modifications introduced to the scoring criterion are given in \citet{Taborda_2013_BSSA}. \citet{Taborda_2013_BSSA, Taborda_2014_BSSA} also include brief discussions regarding the choice of the method proposed by \citet{Anderson_2004_Proc}, in light of other available procedures such as those introduced by \citet{Kristekova_2006_BSSA}, \citet{Kristekova_2009_GJI} or \citet{Olsen_2010_SRL}. In summary, previous experience in verification and validation efforts tells us that the method of \citet{Anderson_2004_Proc} works better for validation, as opposed to verification, mainly because it is not restricted to matching waveforms, but is rather oriented at conveying information of physical meaning to both seismologists and engineers. We also prefer \citet{Anderson_2004_Proc} because it provides additional consistency with respect to previous work done by \citet{Taborda_2013_BSSA, Taborda_2014_BSSA}.
